{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 0. Parte 1. Clasificador lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Enunciado**\n",
    "\n",
    "Desde el análisis de varias muestras de pizarra se infiere que el material se puede clasificar en dos categorías P1 y P2 desde la medición de tres variables (*x*<sub>1</sub>, *x*<sub>2</sub>, *x*<sub>3</sub>). El equipo de ingenieros y y científicos propone entrenar un perceptrón para formar la clasificación de forma automatizada.\n",
    "\n",
    "Utilizando la regla de aprendizaje de Hebb dada por\n",
    "\n",
    "<center>\n",
    "<bold>w</bold>(n + 1) = <bold>w</bold>(n) + (d<sup>(k)</sup> − y) <bold>x</bold><sup>(k)</sup>\n",
    "</center>\n",
    "\n",
    "donde *y* = *σ* (*u*) siendo *u* = **w** ·**x**. Considerando una constante de aprendizaje *η* = 0.01 se pide\n",
    "\n",
    "\n",
    "\n",
    "1. Ejecutar cinco series de entrenamientos del perceptrón inicializando los pesos {**w**} con valores aleatorios (inicializando para cada sesión de entrenamiento si necesario). Los datos de entrenamiento se pueden des- cargar de la página del curso\n",
    "1. escribir los resultados del entrenamiento en una tabla donde se representen los valores de los pesos iniciales y finales para cada una de la sesiones de entrenamiento\n",
    "1. Después de haber entrenado el perceptrón clasificar los datos de la table 1 [indicando](#_page0_x39.69_y395.45) la clase para cada entrada obtenida para las 5 sesiones.\n",
    "1. explicar<a name=\"_page0_x39.69_y395.45\"></a> por qué el número de épocas de entrenamiento varía cada vez que el perceptrón se entrena![](Aspose.Words.042e48d0-77f1-4987-9024-4b991db45e47.002.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Sample|*x*<sub>1</sub>|*x*<sub>2</sub>|*x*<sub>3</sub>|*y* (T1)|*y* (T2)|*y* (T3)|*y* (T4)|*y* (T5)|\n",
    "| - | - | - | - | - | - | - | - | - |\n",
    "|1|-0.3665|0\\.0620|5\\.9891||||||\n",
    "|2|-0.7842|1\\.1267|5\\.5912||||||\n",
    "|3|0\\.3012|0\\.5611|5\\.8234||||||\n",
    "|4|0\\.7757|1\\.0648|8\\.0677||||||\n",
    "|5|0\\.1570|0\\.8028|6\\.3040||||||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import numpy as np\n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Datos de entrenamiento:\n",
    "train = np.array(\n",
    "    [\n",
    "        [\n",
    "            -0.6508,\n",
    "            -1.4492,\n",
    "            2.0850,\n",
    "            0.2626,\n",
    "            0.6418,\n",
    "            0.2569,\n",
    "            1.1155,\n",
    "            0.0914,\n",
    "            0.0121,\n",
    "            -0.0429,\n",
    "            0.4340,\n",
    "            0.2735,\n",
    "            00.4839,\n",
    "            0.4089,\n",
    "            1.4391,\n",
    "            -0.9115,\n",
    "            0.3654,\n",
    "            0.2144,\n",
    "            0.2013,\n",
    "            0.6483,\n",
    "            -0.1147,\n",
    "            -0.7970,\n",
    "            -1.0625,\n",
    "            0.5307,\n",
    "            -1.2200,\n",
    "            0.3957,\n",
    "            -0.1013,\n",
    "            2.4482,\n",
    "            2.0149,\n",
    "            0.2012,\n",
    "        ],\n",
    "        [\n",
    "            0.1097,\n",
    "            0.8896,\n",
    "            0.6876,\n",
    "            1.1476,\n",
    "            1.0234,\n",
    "            0.6730,\n",
    "            0.6043,\n",
    "            0.3399,\n",
    "            0.5256,\n",
    "            0.4660,\n",
    "            0.6870,\n",
    "            1.0287,\n",
    "            0.4851,\n",
    "            -0.1267,\n",
    "            0.1614,\n",
    "            -0.1973,\n",
    "            1.0475,\n",
    "            0.7515,\n",
    "            1.0014,\n",
    "            0.2183,\n",
    "            0.2242,\n",
    "            0.8795,\n",
    "            0.6366,\n",
    "            0.1285,\n",
    "            0.7777,\n",
    "            0.1076,\n",
    "            0.5989,\n",
    "            0.9455,\n",
    "            0.6192,\n",
    "            0.2611,\n",
    "        ],\n",
    "        [\n",
    "            4.0009,\n",
    "            4.4005,\n",
    "            12.0710,\n",
    "            7.7985,\n",
    "            7.0427,\n",
    "            8.3265,\n",
    "            7.4446,\n",
    "            7.0677,\n",
    "            4.6316,\n",
    "            5.4323,\n",
    "            8.2287,\n",
    "            7.1934,\n",
    "            7.4850,\n",
    "            5.5019,\n",
    "            8.5843,\n",
    "            2.1962,\n",
    "            7.4858,\n",
    "            7.1699,\n",
    "            6.5489,\n",
    "            5.8991,\n",
    "            7.2435,\n",
    "            3.8762,\n",
    "            2.4707,\n",
    "            5.6883,\n",
    "            1.7252,\n",
    "            5.6623,\n",
    "            7.1812,\n",
    "            11.2095,\n",
    "            10.9263,\n",
    "            5.4631,\n",
    "        ],\n",
    "        [\n",
    "            -1,\n",
    "            -1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            -1,\n",
    "            -1,\n",
    "            -1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            -1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "        ],\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de activación:\n",
    "def escalon(x: np.ndarray, w: np.ndarray):\n",
    "    '''Devuelve un vector con las salidas de la función escalón para cada entrada de x y el vector de pesos w.'''\n",
    "    return np.where(np.dot(x, w) >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de ejecución con perceptrón\n",
    "def entrenar_perceptron()-> np.ndarray:\n",
    "    '''Enterna un perceptron con los datos previamente definidos.\n",
    "    Devuelve (pesos_iniciales, pesos, error cuadrático medio a lo largo de las ejecuciones, iteraciones realizadas)'''\n",
    "    max_iter = 5000\n",
    "    max_error = 0.0001\n",
    "    mu = 0.01\n",
    "    \n",
    "    x = np.transpose(train[:3])\n",
    "    x = np.insert(x, 0, 1, axis=1) # Añadimos un 1 a las x como x0\n",
    "    d = np.transpose(train[3])\n",
    "    \n",
    "    w = -50 + np.random.rand(4) * 100 # Inicialización aleatoria de los pesos entre -50 y 50\n",
    "    w_inicial = w.copy()\n",
    "    \n",
    "    iteracion = 0\n",
    "    error = inf\n",
    "    errores = []\n",
    "    \n",
    "    while iteracion < max_iter and error > max_error:\n",
    "        y_hat = escalon(x, w)\n",
    "        error_actual = d - y_hat\n",
    "        \n",
    "        # Actualización de pesos\n",
    "        w = w + mu * np.dot(error_actual, x)\n",
    "        \n",
    "        # Calculamos el error cuadrático medio\n",
    "        error = np.mean(np.square(error_actual))\n",
    "        errores.append(error)\n",
    "        \n",
    "        iteracion += 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    return w_inicial, w, errores, iteracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos iniciales\t\t\t\t\tPesos finales\t\t\t\t\t\t\tErrores\t\tIteraciones\n",
      "[39.2051622  -2.87758371 40.17009941 -8.06947655]\t[34.9851622  19.11445629 34.72430941 -8.69654455]\t0.0\t\t455\n",
      "[22.30356177 37.66721229 -9.59019026 15.85361515]\t[23.68356177 10.69535629 15.37430374 -5.22836685]\t0.0\t\t643\n",
      "[-26.45422703 -38.10716013  35.51166172  25.7739562 ]\t[17.84577297  8.62991787 13.87378372 -4.0263998 ]\t0.0\t\t2567\n",
      "[-19.61281131  42.87980416 -13.62985236  32.28936906]\t[17.88718869  8.69825616 14.05135164 -4.04698894]\t0.0\t\t1928\n",
      "[27.12276106 14.48247263 17.56119117  2.04121328]\t[26.24276106 13.17304663 17.54466517 -5.88878672]\t0.0\t\t70\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos 5 veces el perceptrón\n",
    "print(\"Pesos iniciales\\t\\t\\t\\t\\tPesos finales\\t\\t\\t\\t\\t\\t\\tErrores\\t\\tIteraciones\")\n",
    "lista_errores = []\n",
    "pesos_finales = []\n",
    "\n",
    "for i in range(5):\n",
    "    w_inicial, w_final, errores, iteraciones = entrenar_perceptron()\n",
    "    print(f\"{w_inicial}\\t{w_final}\\t{errores[-1]:.5}\\t\\t{iteraciones}\")\n",
    "    lista_errores.append(errores)\n",
    "    pesos_finales.append(w_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta al punto 4:\n",
    "\n",
    "<span style=\"color: DodgerBlue;\">Podemos observar que las iteraciones son siempre inferiores al límite superior establecido (5 000) y además son distintas entre sí.\n",
    "Esto se debe a la inicialización aleatoria y a que no encuentra una sola solución al problema (vemos que los valores de los pesos son distintos entre sí), sino que logra encontrar una que clasifica correctamente el conjunto de entrenamiento.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|     Sample\t|\tx1\t|\tx2\t|\tx3\t|\ty(T1)\t|\ty(T2)\t|\ty(T3)\t|\ty(T4)\t|\ty(T5)\t|\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\t1\t|\t-0.3665\t|\t0.0620\t|\t5.9891\t|\t-1\t|\t-1\t|\t-1\t|\t-1\t|\t-1\t|\n",
      "|\t2\t|\t-0.7842\t|\t1.1267\t|\t5.5912\t|\t1\t|\t1\t|\t1\t|\t1\t|\t1\t|\n",
      "|\t3\t|\t0.3012\t|\t0.5611\t|\t5.8234\t|\t1\t|\t1\t|\t1\t|\t1\t|\t1\t|\n",
      "|\t4\t|\t0.7757\t|\t1.0648\t|\t8.0677\t|\t1\t|\t1\t|\t1\t|\t1\t|\t1\t|\n",
      "|\t5\t|\t0.1570\t|\t0.8028\t|\t6.3040\t|\t1\t|\t1\t|\t1\t|\t1\t|\t1\t|\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculamos valores para rellenar la tabla:\n",
    "\n",
    "test = np.array(\n",
    "    [\n",
    "        [1, -0.3665, 0.0620, 5.9891],\n",
    "        [1, -0.7842, 1.1267, 5.5912],\n",
    "        [1, 0.3012, 0.5611, 5.8234],\n",
    "        [1, 0.7757, 1.0648, 8.0677],\n",
    "        [1, 0.1570, 0.8028, 6.3040],\n",
    "    ]\n",
    ") # Añadimos ya el 1 para poder hacer el cálculo de la salida matricialmente\n",
    "print(\"-\"*145)\n",
    "print(\"|     Sample\\t|\\tx1\\t|\\tx2\\t|\\tx3\\t|\\ty(T1)\\t|\\ty(T2)\\t|\\ty(T3)\\t|\\ty(T4)\\t|\\ty(T5)\\t|\")\n",
    "print(\"-\"*145)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"|\\t{i+1}\\t|\\t{test[i][1]:.4f}\\t|\\t{test[i][2]:.4f}\\t|\\t{test[i][3]:.4f}\\t|\\t{escalon(test[i], pesos_finales[0])}\\t|\\t{escalon(test[i], pesos_finales[1])}\\t|\\t{escalon(test[i], pesos_finales[2])}\\t|\\t{escalon(test[i], pesos_finales[3])}\\t|\\t{escalon(test[i], pesos_finales[4])}\\t|\")\n",
    "print(\"-\"*145)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
