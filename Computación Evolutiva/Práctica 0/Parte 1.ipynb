{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 0. Parte 1. Clasificador lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Enunciado**\n",
    "\n",
    "Desde el análisis de varias muestras de pizarra se infiere que el material se puede clasificar en dos categorías P1 y P2 desde la medición de tres variables (*x*<sub>1</sub>, *x*<sub>2</sub>, *x*<sub>3</sub>). El equipo de ingenieros y y científicos propone entrenar un perceptrón para formar la clasificación de forma automatizada.\n",
    "\n",
    "Utilizando la regla de aprendizaje de Hebb dada por\n",
    "\n",
    "<center>\n",
    "<bold>w</bold>(n + 1) = <bold>w</bold>(n) + (d<sup>(k)</sup> − y) <bold>x</bold><sup>(k)</sup>\n",
    "</center>\n",
    "\n",
    "donde *y* = *σ* (*u*) siendo *u* = **w** ·**x**. Considerando una constante de aprendizaje *η* = 0.01 se pide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ejecutar cinco series de entrenamientos del perceptrón inicializando los pesos {**w**} con valores aleatorios (inicializando para cada sesión de entrenamiento si necesario). Los datos de entrenamiento se pueden des- cargar de la página del curso\n",
    "1. escribir los resultados del entrenamiento en una tabla donde se representen los valores de los pesos iniciales y finales para cada una de la sesiones de entrenamiento\n",
    "1. Después de haber entrenado el perceptrón clasificar los datos de la table 1 [indicando](#_page0_x39.69_y395.45) la clase para cada entrada obtenida para las 5 sesiones.\n",
    "1. explicar<a name=\"_page0_x39.69_y395.45\"></a> por qué el número de épocas de entrenamiento varía cada vez que el perceptrón se entrena![](Aspose.Words.042e48d0-77f1-4987-9024-4b991db45e47.002.png)\n",
    "\n",
    "\n",
    "\n",
    "|Sample|*x*<sub>1</sub>|*x*<sub>2</sub>|*x*<sub>3</sub>|*y* (T1)|*y* (T2)|*y* (T3)|*y* (T4)|*y* (T5)|\n",
    "| - | - | - | - | - | - | - | - | - |\n",
    "|1|-0.3665|0\\.0620|5\\.9891||||||\n",
    "|2|-0.7842|1\\.1267|5\\.5912||||||\n",
    "|3|0\\.3012|0\\.5611|5\\.8234||||||\n",
    "|4|0\\.7757|1\\.0648|8\\.0677||||||\n",
    "|5|0\\.1570|0\\.8028|6\\.3040||||||\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento:\n",
    "train = np.array(\n",
    "    [\n",
    "        [\n",
    "            -0.6508,\n",
    "            -1.4492,\n",
    "            2.0850,\n",
    "            0.2626,\n",
    "            0.6418,\n",
    "            0.2569,\n",
    "            1.1155,\n",
    "            0.0914,\n",
    "            0.0121,\n",
    "            -0.0429,\n",
    "            0.4340,\n",
    "            0.2735,\n",
    "            00.4839,\n",
    "            0.4089,\n",
    "            1.4391,\n",
    "            -0.9115,\n",
    "            0.3654,\n",
    "            0.2144,\n",
    "            0.2013,\n",
    "            0.6483,\n",
    "            -0.1147,\n",
    "            -0.7970,\n",
    "            -1.0625,\n",
    "            0.5307,\n",
    "            -1.2200,\n",
    "            0.3957,\n",
    "            -0.1013,\n",
    "            2.4482,\n",
    "            2.0149,\n",
    "            0.2012,\n",
    "        ],\n",
    "        [\n",
    "            0.1097,\n",
    "            0.8896,\n",
    "            0.6876,\n",
    "            1.1476,\n",
    "            1.0234,\n",
    "            0.6730,\n",
    "            0.6043,\n",
    "            0.3399,\n",
    "            0.5256,\n",
    "            0.4660,\n",
    "            0.6870,\n",
    "            1.0287,\n",
    "            0.4851,\n",
    "            -0.1267,\n",
    "            0.1614,\n",
    "            -0.1973,\n",
    "            1.0475,\n",
    "            0.7515,\n",
    "            1.0014,\n",
    "            0.2183,\n",
    "            0.2242,\n",
    "            0.8795,\n",
    "            0.6366,\n",
    "            0.1285,\n",
    "            0.7777,\n",
    "            0.1076,\n",
    "            0.5989,\n",
    "            0.9455,\n",
    "            0.6192,\n",
    "            0.2611,\n",
    "        ],\n",
    "        [\n",
    "            4.0009,\n",
    "            4.4005,\n",
    "            12.0710,\n",
    "            7.7985,\n",
    "            7.0427,\n",
    "            8.3265,\n",
    "            7.4446,\n",
    "            7.0677,\n",
    "            4.6316,\n",
    "            5.4323,\n",
    "            8.2287,\n",
    "            7.1934,\n",
    "            7.4850,\n",
    "            5.5019,\n",
    "            8.5843,\n",
    "            2.1962,\n",
    "            7.4858,\n",
    "            7.1699,\n",
    "            6.5489,\n",
    "            5.8991,\n",
    "            7.2435,\n",
    "            3.8762,\n",
    "            2.4707,\n",
    "            5.6883,\n",
    "            1.7252,\n",
    "            5.6623,\n",
    "            7.1812,\n",
    "            11.2095,\n",
    "            10.9263,\n",
    "            5.4631,\n",
    "        ],\n",
    "        [\n",
    "            -1,\n",
    "            -1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            -1,\n",
    "            -1,\n",
    "            -1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            -1,\n",
    "            -1,\n",
    "            1,\n",
    "            -1,\n",
    "            1,\n",
    "        ],\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de activación:\n",
    "def escalon(x: np.ndarray, w: np.ndarray):\n",
    "    '''Devuelve un vector con las salidas de la función escalón para cada entrada de x y el vector de pesos w.'''\n",
    "    return np.where(np.dot(x, w) >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de ejecución con perceptrón\n",
    "def entrenar_perceptron()-> np.ndarray:\n",
    "    '''Enterna un perceptron con los datos previamente definidos.\n",
    "    Devuelve (pesos_iniciales, pesos, error cuadrático medio a lo largo de las ejecuciones)'''\n",
    "    max_iter = 1000\n",
    "    max_error = 0.0001\n",
    "    mu = 0.01\n",
    "    \n",
    "    x = np.transpose(train[:3])\n",
    "    x = np.insert(x, 0, 1, axis=1) # Añadimos un 1 a las x como x0\n",
    "    d = np.transpose(train[3])\n",
    "    \n",
    "    w = np.random.rand(4)\n",
    "    w_inicial = w.copy()\n",
    "    \n",
    "    iteracion = 0\n",
    "    error = inf\n",
    "    errores = []\n",
    "    \n",
    "    while iteracion < max_iter and error > max_error:\n",
    "        y_hat = escalon(x, w)\n",
    "        error_actual = d - y_hat\n",
    "        \n",
    "        # Actualización de pesos\n",
    "        w = w + mu * np.dot(error_actual, x)\n",
    "        \n",
    "        # Calculamos el error cuadrático medio\n",
    "        error = np.mean(np.square(error_actual))\n",
    "        errores.append(error)\n",
    "        \n",
    "    \n",
    "    \n",
    "    return w_inicial, w, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos iniciales\t\t\t\t\tPesos finales\t\t\t\t\t\tErrores\n",
      "[0.66173549 0.19643196 0.52446565 0.28990543]\t[17.90173549  8.73733596 14.15687365 -4.05887857]\t0.0\n",
      "[0.24935269 0.80382097 0.78508404 0.46204696]\t[17.68935269  8.59584097 13.83775204 -4.08492104]\t0.0\n",
      "[0.02676186 0.64868961 0.6852228  0.82782671]\t[17.88676186  8.72850561 14.1373188  -4.05717929]\t0.0\n",
      "[0.99357225 0.96821178 0.20564244 0.32781746]\t[17.87357225  8.67209578 14.01993044 -4.04052854]\t0.0\n",
      "[0.82552072 0.64477181 0.26060537 0.07082074]\t[17.76552072  8.60584781 13.84748537 -4.01007726]\t0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos 5 veces el perceptrón\n",
    "print(\"Pesos iniciales\\t\\t\\t\\t\\tPesos finales\\t\\t\\t\\t\\t\\tErrores\")\n",
    "for i in range(5):\n",
    "    w_inicial, w_final, errores = entrenar_perceptron()\n",
    "    print(f\"{w_inicial}\\t{w_final}\\t{errores[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
